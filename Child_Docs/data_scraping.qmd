---
title: "Data Scraping"
---

```{r}
library(parallel)

library(parallel)

#| label: "combine-csv-files-parallel"
#| echo: true
#| message: false
#| warning: false
#| code-fold: true

# Step 2: List all CSV files in the directory
csv_files <- list.files(path = csv_directory, pattern = "*.csv", full.names = TRUE)

# Step 3: Define a function to read and process each CSV file
read_csv_file <- function(file) {
  data <- read.csv(file, sep = " ", header = FALSE)  # Read the CSV file
  data$FileName <- gsub("\\.[^.]*$", "", basename(file))  # Remove the file extension
  return(data)
}

# Step 4: Set up for parallel processing
num_cores <- detectCores() - 1  
cluster_type <- ifelse(.Platform$OS.type == "windows", "PSOCK", "FORK") 

# Step 5: Create and run the cluster
cl <- makeCluster(num_cores, type = cluster_type)
clusterExport(cl, c("read_csv_file", "gsub", "basename"))
combined_data <- do.call(rbind, parLapply(cl, csv_files, read_csv_file))
stopCluster(cl)  # Stop the cluster after processing

# Return the combined data
combined_data

```
